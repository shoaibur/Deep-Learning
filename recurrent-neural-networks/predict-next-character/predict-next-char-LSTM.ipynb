{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/anna.txt','r') as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(set(text))\n",
    "char2int = {ch:ind for ind, ch in enumerate(tokens)}\n",
    "text2int = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "    '''    \n",
    "    # Get the number of batches\n",
    "    full_batch_size = batch_size * seq_length\n",
    "    n_batches = len(arr) // full_batch_size\n",
    "    \n",
    "    # Remove unused elements from the end of arr\n",
    "    use_len = n_batches * full_batch_size\n",
    "    arr = arr[:use_len]\n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape(batch_size,-1)\n",
    "    \n",
    "    ## Iterate over the batches using a window of size seq_length\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:(n+seq_length)] # Training data\n",
    "        y = np.roll(x,-1) # Target = circular left shift of x by 1\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, tokens, n_hidden=16, n_layers=1, drop_prob=0.5):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.tokens = tokens\n",
    "        self.char2int = {ch:ind for ind, ch in enumerate(self.tokens)}\n",
    "        self.int2char = {ind:ch for ind, ch in enumerate(self.tokens)}\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(len(self.tokens), self.n_hidden, self.n_layers,\n",
    "                            dropout=self.drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        self.fc = nn.Linear(self.n_hidden, len(self.tokens))\n",
    "                \n",
    "    def forward(self, x, hidden):\n",
    "        x, hidden = self.lstm(x, hidden)\n",
    "        x = self.dropout(x)\n",
    "        if self.n_layers > 1:\n",
    "            x = x.contiguous()\n",
    "        x = x.view(-1, self.n_hidden)\n",
    "        x = self.fc(x)\n",
    "        return x, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Check if GPU is available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, xtrain, n_epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1):\n",
    "    ''' \n",
    "    Input arguments:\n",
    "    ---------------\n",
    "    model -- model to train\n",
    "    data -- training data\n",
    "    clip -- threshold to avoid exploding gradient problem\n",
    "    val_frac -- fraction of data will be used for validation\n",
    "    '''\n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.train() # Keep model in training mode\n",
    "    model = model.to(device) # Send model to GPU, if available\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Split train and validation data\n",
    "    val_idx = int(len(xtrain)*(1-val_frac))\n",
    "    xtrain, xvalid = xtrain[:val_idx], xtrain[val_idx:]\n",
    "\n",
    "    train_loss_epochs = []\n",
    "    valid_loss_epochs = []\n",
    "    min_valid_loss = np.inf\n",
    "    n_tokens = len(model.tokens)\n",
    "    for iepoch in range(n_epochs):\n",
    "        # initialize hidden state\n",
    "        h = model.init_hidden(batch_size)\n",
    "        train_loss_batch = []\n",
    "        for ibatch, (x, y) in enumerate(get_batches(xtrain, batch_size, seq_length)):\n",
    "            if (iepoch+1)%1 == 0:\n",
    "                progress = (ibatch+1) / (len(xtrain) // (batch_size * seq_length)) * 100\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write('\\rEpoch {}/{} ... {:0.2f}% ... '\n",
    "                                 .format(iepoch+1, n_epochs, progress))\n",
    "            \n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_tokens)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.long().to(device)\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(batch_size*seq_length))\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_batch.append(loss.item())\n",
    "        train_loss_epochs.append( np.mean(train_loss_batch) )\n",
    "        \n",
    "        # Get validation loss\n",
    "        val_h = model.init_hidden(batch_size)\n",
    "        valid_loss_batch = []\n",
    "        model.eval()\n",
    "        for x, y in get_batches(xvalid, batch_size, seq_length):\n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = one_hot_encode(x, n_tokens)\n",
    "            x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            inputs, targets = x, y\n",
    "            inputs, targets = inputs.to(device), targets.long().to(device)\n",
    "\n",
    "            output, val_h = model(inputs, val_h)\n",
    "            val_loss = criterion(output, targets.view(batch_size*seq_length))\n",
    "\n",
    "            valid_loss_batch.append(val_loss.item())\n",
    "\n",
    "        model.train() # reset to train mode after iterationg through validation data\n",
    "        \n",
    "        # Accumulate training validation loss over the epochs\n",
    "        valid_loss_epochs.append(np.mean(valid_loss_batch))\n",
    "        # Update min_valid_loss and save model\n",
    "        if valid_loss_epochs[iepoch] < min_valid_loss:\n",
    "            min_valid_loss = valid_loss_epochs[iepoch]\n",
    "            model_name = 'next-char-predict-lstm.net'\n",
    "            checkpoint = {'n_hidden': model.n_hidden,\n",
    "                          'n_layers': model.n_layers,\n",
    "                          'state_dict': model.state_dict(),\n",
    "                          'tokens': model.tokens}\n",
    "            with open(model_name, 'wb') as f:\n",
    "                torch.save(checkpoint, f)\n",
    "        # Display losses\n",
    "        if (iepoch+1)%1 == 0:\n",
    "            print(\"Training loss: {:.4f}...\".format(train_loss_epochs[iepoch]),\n",
    "                  \"Validation loss: {:.4f}\".format(valid_loss_epochs[iepoch]))\n",
    "    return train_loss_epochs, valid_loss_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharLSTM(\n",
      "  (lstm): LSTM(57, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=57, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = CharLSTM(tokens, n_hidden, n_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 ... 100.00% ... Training loss: 3.0241... Validation loss: 2.5851\n",
      "Epoch 2/20 ... 100.00% ... Training loss: 2.3613... Validation loss: 2.1340\n",
      "Epoch 3/20 ... 100.00% ... Training loss: 2.0498... Validation loss: 1.8934\n",
      "Epoch 4/20 ... 100.00% ... Training loss: 1.8621... Validation loss: 1.7420\n",
      "Epoch 5/20 ... 100.00% ... Training loss: 1.7370... Validation loss: 1.6397\n",
      "Epoch 6/20 ... 100.00% ... Training loss: 1.6509... Validation loss: 1.5681\n",
      "Epoch 7/20 ... 100.00% ... Training loss: 1.5869... Validation loss: 1.5163\n",
      "Epoch 8/20 ... 100.00% ... Training loss: 1.5358... Validation loss: 1.4769\n",
      "Epoch 9/20 ... 100.00% ... Training loss: 1.4960... Validation loss: 1.4481\n",
      "Epoch 10/20 ... 100.00% ... Training loss: 1.4622... Validation loss: 1.4205\n",
      "Epoch 11/20 ... 100.00% ... Training loss: 1.4341... Validation loss: 1.4008\n",
      "Epoch 12/20 ... 100.00% ... Training loss: 1.4086... Validation loss: 1.3851\n",
      "Epoch 13/20 ... 100.00% ... Training loss: 1.3869... Validation loss: 1.3681\n",
      "Epoch 14/20 ... 100.00% ... Training loss: 1.3683... Validation loss: 1.3558\n",
      "Epoch 15/20 ... 100.00% ... Training loss: 1.3504... Validation loss: 1.3434\n",
      "Epoch 16/20 ... 100.00% ... Training loss: 1.3350... Validation loss: 1.3372\n",
      "Epoch 17/20 ... 100.00% ... Training loss: 1.3214... Validation loss: 1.3288\n",
      "Epoch 18/20 ... 100.00% ... Training loss: 1.3066... Validation loss: 1.3113\n",
      "Epoch 19/20 ... 100.00% ... Training loss: 1.2896... Validation loss: 1.3038\n",
      "Epoch 20/20 ... 100.00% ... Training loss: 1.2759... Validation loss: 1.2940\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "seq_length = 100\n",
    "val_frac = 0.1\n",
    "n_epochs =  20\n",
    "\n",
    "# train the model\n",
    "train_loss, valid_loss = train(model, text2int, n_epochs=n_epochs, batch_size=batch_size,\n",
    "                               seq_length=seq_length, lr=0.001, val_frac=val_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(valid_loss, label='Valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, char, hidden=None, top_k=None):\n",
    "    ''' Given a character, predict the next character.\n",
    "        Returns the predicted character and the hidden state.\n",
    "    '''        \n",
    "    # tensor inputs\n",
    "    x = np.array([[model.char2int[char]]])\n",
    "    x = one_hot_encode(x, len(model.tokens))\n",
    "    inputs = torch.from_numpy(x)\n",
    "\n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Detach hidden state from history\n",
    "    hidden = tuple([each.data for each in hidden])\n",
    "    # get the output of the model\n",
    "    outputs, hidden = model(inputs, hidden)\n",
    "\n",
    "    # Get character probabilities\n",
    "    p = F.softmax(outputs, dim=1).data\n",
    "    p = p.to('cpu') # move to cpu\n",
    "\n",
    "    # Top characters\n",
    "    if top_k is None:\n",
    "        top_ch = np.arange(len(model.tokens))\n",
    "    else:\n",
    "        p, top_ch = p.topk(top_k)\n",
    "        top_ch = top_ch.numpy().squeeze()\n",
    "\n",
    "    # select the likely next character with some element of randomness\n",
    "    p = p.numpy().squeeze()\n",
    "    token_int = np.random.choice(top_ch, p=p/p.sum())\n",
    "    char = model.int2char[token_int]\n",
    "    # return the encoded value of the predicted char and the hidden state\n",
    "    return char, hidden\n",
    "\n",
    "\n",
    "def sample(model, size, prime='The', top_k=None):\n",
    "        \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval() # eval mode\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    hidden = model.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, hidden = predict(model, ch, hidden, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, hidden = predict(model, chars[-1], hidden, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('next-char-predict-lstm.net', 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "    \n",
    "model = CharLSTM(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anna, however thought it is\n",
      "starting from a smile, but in the portrait of them, and the peasants our ofting the\n",
      "starts of his brother's action to always seem that it was so much at horrow on them, and then the passions they\n",
      "were a service. if they will be different., it's such a studie words, to\n",
      "go all to be a corpanion at other stead that, i should have\n",
      "something thinking. you're not\n",
      "tonnur about in the simpless of making any man into his\n",
      "son, but his wife then there's no offort, and to stepan\n",
      "arkadyevitch where said: to be that more well as\n",
      "a stupid of a pleasuse, where i see. indeed you had not to\n",
      "be the bedune in those persence.... and i see than it was\n",
      "nine a times and an to the men of my frunh, but i don't call a long, as\n",
      "they, i sand in serious, as it's natural, and they dressed in\n",
      "the peasants was an expected of the calles.\"\n",
      "\n",
      "\"and there was stiva!\" he thought, \"what is!\" she thought,\n",
      "sitcing to him to the country, silkny with the same\n",
      "princess that wear hands of the memory of the pranenss of\n",
      "him all this setrice in his chief second, that she can\n",
      "through her that she would not sat those hands on his\n",
      "high train.\n",
      "\n",
      "\"well, i ask him i should be at the\n",
      "same thing.\"\n",
      "\n",
      "\"you won't blame to have to see how it's to be the\n",
      "broad truth.\"\n",
      "\n",
      "\"yes, you won't soon have seemed and so as for terrach and terribles,\n",
      "and the most infirmation of this wishoved, the man in their part to\n",
      "the crowd.\n",
      "\n",
      "\"yes, all the same all alone, and she will see, all\n",
      "that the peasants, that i cannot come out in three.\"\n",
      "\n",
      "\"that's so talk, that i wanted to. i dance her have so muck,\n",
      "as he did not get on that is at the priest. there's no hurry and\n",
      "incepenal impolting on the poor atsitute, i said to this\n",
      "music. thank i have been taken on me. and haven't been\n",
      "dinner.\"\n",
      "\n",
      "\"there's no one was an instant, if you hand, stepan arkadyevitch,\" he thought. \"what's\n",
      "it you mind,\" she added, with saying his starr and\n",
      "crousing hours and saying it with an end.\n",
      "\n",
      "\"well, and you would go and makes any castiness, all that\n",
      "man want \n"
     ]
    }
   ],
   "source": [
    "prime = 'Anna'.lower()\n",
    "print(sample(model, 2000, prime=prime, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
